{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "om-YAJ2bwWhR"
   },
   "source": [
    "# **Fine tuning a NLP model for persian question answering from a pre-trained Hugging Face's transformer model and Building Custom Question Answering Bot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fFH8-566KipK",
    "outputId": "aad13ff7-965d-4205-ef13-7ed228f337cf"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcQRxpA9xyWP"
   },
   "source": [
    "# **1- Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2Q94hdXLsrM"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_squad(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        squad_dict = json.load(f)\n",
    "\n",
    "    # initialize lists for contexts, questions, and answers\n",
    "    contexts = []\n",
    "    questions = []\n",
    "    answers = []\n",
    "    # iterate through all data in squad data\n",
    "    for group in squad_dict['data']:\n",
    "        for passage in group['paragraphs']:\n",
    "            context = passage['context']\n",
    "            for qa in passage['qas']:\n",
    "                question = qa['question']\n",
    "                if 'plausible_answers' in qa.keys():\n",
    "                    access = 'plausible_answers'\n",
    "                else:\n",
    "                    access = 'answers'\n",
    "                for answer in qa['answers']:\n",
    "                    # append data to lists\n",
    "                    contexts.append(context)\n",
    "                    questions.append(question)\n",
    "                    answers.append(answer)\n",
    "    # return formatted data lists\n",
    "    return contexts, questions, answers\n",
    "\n",
    "# apply function\n",
    "train_contexts, train_questions, train_answers = read_squad('/content/gdrive/MyDrive/train_persian_llm.json')\n",
    "val_contexts, val_questions, val_answers = read_squad('/content/gdrive/MyDrive/test_persian_llm.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgBWgzSlx6OX"
   },
   "source": [
    "# **2- Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbGwVH6yMYg9"
   },
   "outputs": [],
   "source": [
    "def create_answers_dict(x):\n",
    "    dict_ = {\"text\":[(x[\"answer\"])], \"answer_start\":[(int(x[\"answer_start\"]))]}\n",
    "    return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "T4NuN9Q_Mbsa",
    "outputId": "dcc1d38a-bd27-4966-f49a-ef169177f597"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#train\n",
    "contexts_df_train = pd.DataFrame(train_contexts, columns=['context'])\n",
    "questions_df_train = pd.DataFrame(train_questions, columns=['question'])\n",
    "answers_df_train = pd.DataFrame.from_records(train_answers)\n",
    "df_train = contexts_df_train.copy()\n",
    "df_train[\"question\"] = questions_df_train[\"question\"]\n",
    "df_train[\"answer\"] = answers_df_train[\"text\"]\n",
    "df_train[\"answer_start\"] = answers_df_train[\"answer_start\"]\n",
    "df_train.reset_index(inplace=True, drop = False)\n",
    "df_train.rename(columns={'index':'id'}, inplace=True)\n",
    "df_train[\"answers\"] = df_train.apply(lambda x: create_answers_dict(x), axis = 1)\n",
    "\n",
    "#test\n",
    "contexts_df_test = pd.DataFrame(val_contexts, columns=['context'])\n",
    "questions_df_test = pd.DataFrame(val_questions, columns=['question'])\n",
    "answers_df_test = pd.DataFrame.from_records(val_answers)\n",
    "df_test = contexts_df_test.copy()\n",
    "df_test[\"question\"] = questions_df_test[\"question\"]\n",
    "df_test[\"answer\"] = answers_df_test[\"text\"]\n",
    "df_test[\"answer_start\"] = answers_df_test[\"answer_start\"]\n",
    "df_test.reset_index(inplace=True, drop = False)\n",
    "df_test.rename(columns={'index':'id'}, inplace=True)\n",
    "df_test[\"answers\"] =  df_test.apply(lambda x: create_answers_dict(x), axis = 1)\n",
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIh4-VrXMhYZ"
   },
   "outputs": [],
   "source": [
    "df_train.sample(frac = 0.5)[['id', 'context', 'question', 'answers']].to_csv('/content/gdrive/MyDrive/dataset_train.csv', index=False)\n",
    "df_test.sample(frac = 0.5)[['id', 'context', 'question', 'answers']].to_csv('/content/gdrive/MyDrive/dataset_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBcsc1mmNDDJ"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260,
     "referenced_widgets": [
      "7982c6066ef345d8a29cbf544d17c43a",
      "f99dc4f5c7e14edfb28d9d3f3f6fcef8",
      "0789f089e6eb4609bb4e2a65ea912581",
      "06835a0314ab45f49c2e580773d47099",
      "78149a9a01ac4a748221261eb033e55d",
      "b8c0ee5dced74f60a0f822947000846f",
      "190639e0968046f6aa3317af4b4f1eed",
      "ad0729c6fa704168b7799886cbb9d406",
      "cacb5109368c4913a78f1d9bb7459e85",
      "0b00fbc550934261ab0be32864bd1d9a",
      "417d05146e154e3fa7549a872d73be5a",
      "773e2277b1564ab7bdc6d89f63b3a140",
      "67d94b936e50457da5ad5c94d6936383",
      "1441438a3c79416f8ffac42537391b26",
      "4c46a28018814166ace24c90eb75ffd3",
      "e5260268515b4b3d8fe4dccc351486e6",
      "1c113f6cd71b4b14b651cc12293d73bd",
      "adef8b7d21e7456490d75e5d63a268c8",
      "3b9db47266ab41e08af699cdb1ad6a3e",
      "505b646b054f4c2f94e0b3051d23113a",
      "2b65eecd12b84dc09987f459101cce13",
      "19e7cb85e913461c997532180bfd0cbb"
     ]
    },
    "id": "jk62jKNsMuoU",
    "outputId": "6d6b7210-9b06-4023-86c1-888bc82eaef7"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\"train\": \"/content/gdrive/MyDrive/dataset_train.csv\", \"test\": \"/content/gdrive/MyDrive/dataset_test.csv\"}\n",
    "ds = load_dataset(\"csv\", data_files=data_files)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "523de8eecf8f4221b3fa92c8eebde97f",
      "c48c4fb47147480d943ac2e139f478b1",
      "50c9483d3df342d497d62c48f66ec92f",
      "b27bd2767f1942cab1b90a2e8ca12e9a",
      "84a3471b2f1647c7b72e680a22b716f5",
      "4887643ffc3e4647b3bce376eb663ce8",
      "cd91258dd6e04ea5b0f565fa06dc86e0",
      "d3589f2dc7e6475894cd6d3f4c96f8f6",
      "5a4c8e103103431abfa8fd4ed8881c7e",
      "d7075a8487944f79b5069d3491558a96",
      "54fa040432344d0396908bd29859112e",
      "ad91d607aec34180a65a662a963d2945",
      "5a979777e270460ab7a4f71a320f71b2",
      "7727c5732120479aa2ada2aa3e63436e",
      "591bfa69f0724255bb87465bd1efdb98",
      "7628e2bff8da4c5094b8034e921b6ab9",
      "93f2fd665dfa4514b6e5b6dffa706276",
      "72602847b6574b5abd5db50c055513f6",
      "7e43131a73794433a8b3a61c2fb08ff6",
      "43422a731a0b42f98c9a7b23bee31fad",
      "c133ceabf4b142f4b5993b02d3a73cb2",
      "e13fb25c9deb4aab8c08f04319a243c5"
     ]
    },
    "id": "HmqLJlF6NLHy",
    "outputId": "1b86e0a1-5a17-487c-a49d-81b78dce3741"
   },
   "outputs": [],
   "source": [
    "def convert_text(batch):\n",
    "  aux_list = []\n",
    "  for x, y in zip(batch[\"answers\"], batch[\"answers\"]):\n",
    "    my_dict = {\"text\":eval(x)[\"text\"], \"answer_start\":eval(x)[\"answer_start\"]}\n",
    "    aux_list.append(my_dict)\n",
    "\n",
    "  return {\"texts\":aux_list}\n",
    "\n",
    "prepared_ds = ds.map(convert_text, batched = True)\n",
    "prepared_ds = prepared_ds.remove_columns(\"answers\")\n",
    "prepared_ds = prepared_ds.rename_column(\"texts\", \"answers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RK-o3O93yWbG"
   },
   "source": [
    "# **3- Tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252,
     "referenced_widgets": [
      "5318dfda1faa45cd9c33a90f233a1515",
      "66d3c75a50564b77b60e08d7a859f8c0",
      "d0e55afa5bb1452d97461d037fee40eb",
      "c0290ee70629404bb5ce08b0574be56d",
      "3ad91435f8834d0e8d5932bffc400ce0",
      "a2fdae2803ae45a49b1b6f2a153cba8a",
      "5c9382fe18cc44a2a0c02fb8c6bcdd69",
      "81972c8deca54c288a4cd65b0d9763a1",
      "94d7998b0fe54c8983c8ae56da57f15f",
      "2bf468772fa94d6d8200f6b4fd8d39d1",
      "e40321b85b59422b9fb4feaf143db6f5",
      "ccf63889c88642d3bfab9960c6120cae",
      "d7ad80083d6744d8823c95c356aedd78",
      "fe33185f2c0446a6af756b660dcee973",
      "cad9b909c1f24cbd9653b1bcbbb94751",
      "97a5ba2724684142a85e4331496cfb34",
      "702f81b816c84696b2f424c291fd582c",
      "8b00d680fd0344a4ba39bb95003c598b",
      "1b909390c35947c9b5451f555a284ef9",
      "7285286a3182451cae65f48123820787",
      "4fd253ece08d41aa92a7490fc2bd7aeb",
      "7f92920a0971487e9da9377efdb8af66",
      "b8f40eb2838e48e7aca2330ee5cfc6a1",
      "21e108dc00924b339249eb66adedbe88",
      "b2c8cb0c744443d0b291bdc648d0ca68",
      "7d8d3b5a1cb040758169ac0b8df7821a",
      "ca1cd4725bf34fcfb249e6cf90053556",
      "dd97933eb7cb4dc8a2ce3907a059f8bd",
      "53e7e2c9af704b46a269d78a598c2173",
      "c23fd5e8b8644d8d91f189f8ffbdfeeb",
      "5e75785410114f349740c37c352cd2f8",
      "c19de325fd6749c1ab896d013fd8fd73",
      "defc910489b24a6482a4ebf02cbdc8af",
      "a0c6364c9eaa437e99ff2a26c2fc4f4f",
      "70f7686b71754ba0913200f28748e1cb",
      "396e1119eb204ef4891f1ed815e66864",
      "e5668607973e4afaa7891e657c8f9182",
      "413edf14474e41a4a4f7ab6c700257da",
      "6d77376201ed476bb9021bcd13208722",
      "626332f7484445beaa014f2e9903f7d6",
      "d38b3730123545f59d187b9c2f96eb2f",
      "c439ac50275b4b9bbe517f9644d9af29",
      "8948301a535042a7b7c0ecec22d8e087",
      "1e612302092646e1ae04dc9f81c4663b"
     ]
    },
    "id": "ThBEeI9ENR9J",
    "outputId": "66f0636a-ac88-4275-c357-3f639f6a7830"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    print(offset_mapping)\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315,
     "referenced_widgets": [
      "2aa6b32fe98d4af5b316c6cf49b0aa73",
      "98985e7730774c0c97b54508d9c97130",
      "09831b9803844840b12019a0df1362ea",
      "5fc4ac753a154147aa1eddc26be50203",
      "3fe2c360375f4e4daaf839ddd3a01a22",
      "de696899dd774f928c4ce9a84abec4d1",
      "59574e8f9c80485492059c1171c3fad0",
      "4218061d9f834340924fc34b956564ea",
      "0381c0c028b9453e98860e78abc4ad05",
      "0bfd420aa91f47b3b07ef39c47f084e4",
      "29a654a0243046e19dce329c29480968",
      "65fd41d69830445399af562d8ad4a5a3",
      "3949db49b084483c8036b2e95b90618a",
      "daff81aeaf2846068d00ebd254fbd070",
      "7ff54a49dc684328a9e7695c8f47eb9e",
      "53c5fefda4e54c57bba28f346569d724",
      "1dec9b49100340fdb7f92aef27b60cb4",
      "c75638044f534984a614c667968c1071",
      "e4a67cb034cc435f91ebee6f7ed1aa4e",
      "09ec031a3a4e47d38eeb8bebf6e3b34f",
      "a422fbd4848e45cdaede98ff2cd97ce6",
      "a51e352989434f02bbe960a5e6f5b488"
     ]
    },
    "id": "xd2S0p_1NakW",
    "outputId": "70c92e99-c4bd-4c21-f7e9-9d64b1fcd0e8"
   },
   "outputs": [],
   "source": [
    "tokenized_squad = prepared_ds.map(preprocess_function, batched=True, remove_columns=ds[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwbMMdE5yhLh"
   },
   "source": [
    "# **4- Login to Hugging Face**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "0cdba8266bb34de3a2817a35bb21cac2",
      "c8b677f50f7d4516a7a1005526ee3031",
      "b1f0eff3768c48e3b04153accbc48e62",
      "0196f07af4b54020a587a179d0dcba9b",
      "ddfd679b88ae4af1847200364cfba081",
      "dd7a6e600ef549dd9023d84fc9ffaea9",
      "3a8c128473284c7a97ff119933fb4237",
      "26079e28b571427c9c7feef8d611b8a7",
      "0fe1ad88c2c14fbca59de8cf3100cbff",
      "b1fee37390a645398f15a9c4891afe49",
      "361f3408aa3943608b5fb32b733925c6",
      "5d66d7330aef406da2bc5ca2a55a3911",
      "656510d5225a459cb2cb1ef6ba818966",
      "5a1776eae727493b809d7d2eaeb1e9e6",
      "48a89346a17f41a49e2a1b17a326bdc2",
      "bd6ae7333710472eb5d9742fb5e47491",
      "a65569720ed344ed9acf4cb8b90612b1",
      "fc10a4b6bded416d9f0b362851b9d8d2",
      "d352327277db44fd817b06afa83ba941",
      "f0767c582f374b71a2161f36319831fb"
     ]
    },
    "id": "ZdiG3tu6Nmsg",
    "outputId": "4cfa3d46-32bd-4520-f370-81b1b88da13c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "HUGGING_FACE_API_KEY = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "login(token = HUGGING_FACE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ki8B0MnoypH_"
   },
   "source": [
    "# **5- Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "ZUO95OelPmAe",
    "outputId": "58a33a3b-ee19-41ca-cdfb-a88c637b7f2b"
   },
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"qa_nlp_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"none\",\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_squad[\"train\"],\n",
    "    eval_dataset=tokenized_squad[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qYtSIgiyxAk"
   },
   "source": [
    "# **6- Save model & Push to Hugging Face Hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "KI0FGjv-P2Lt",
    "outputId": "845f9470-cc0d-4ee1-e693-e476098cafd1"
   },
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "metrics = trainer.evaluate(tokenized_squad[\"test\"])\n",
    "\n",
    "kwargs = {\n",
    "    \"finetuned_from\": model.config._name_or_path,\n",
    "    \"tasks\": \"question-answering\",\n",
    "    \"dataset\": \"squad\",\n",
    "    \"tags\":[\"persian\",\"question-answering\", \"nlp\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "wFxHWQyOQMk8",
    "outputId": "e55064a8-94ce-4e3a-e5fc-c8ba3d7bf5b4"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub(commit_message = \"persian question answering model tuned\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXboJiLt56lR"
   },
   "source": [
    "# **7- Load Model from Huggingface with Transformers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227,
     "referenced_widgets": [
      "f9dd54cb28904b06a15c7f28d3f6d2ac",
      "33781c5d6e4942328e5a8e0a97150a39",
      "c54e1707321e485cb06bbe4628fbd2d4",
      "ad8b75f610da4a92883853ed97fd1b29",
      "0503a19169fa4832a2e9043cb0169b4e",
      "610f21d773654ad4b6daa3f84761367a",
      "12a1961784844bef9761df1fa194134c",
      "563820feb4904772a75887cbf9ec3e80",
      "b96005b9a0044fbe8cf99e0ec067d9c3",
      "67f689bf978a4707b0211cf78811b496",
      "a6f7d23611274a5dbc3e1f3faab4b16d",
      "30ff13e708bf4a3db31700e60dd206c0",
      "921d003988ba47b28d1c8e1af0861299",
      "d5381481df8d4673bb441e9d0f5115cd",
      "8392215220d84cd9853c117f88f129a5",
      "fc198eb23dff43d4a4f244d21d05cc74",
      "80adbf2cb59841bdb14c1195adb4e43f",
      "b5cc0dd7a2a04ace83fd2d8a2aef3de9",
      "6113dd2efb7045b88ed84b7f562cc5d7",
      "bdff1f0b9a0549cfb6b58751561d8303",
      "a7ebc22514a54610a142c1c810610974",
      "d05886a4d1d547ebbb27dc44c45bddcb",
      "eff197ecfcb94d4c90d5093341ee7b8e",
      "2aa1a8d481124366808bf10e5dfafd77",
      "b6a074c5fa3143419383f231d366c8b0",
      "adbef94386b246ab8a2c0bcad39e6288",
      "f4a9c642e259418ebd353fc83da4c8dc",
      "35d79fd87a5f41f594001fcd3d6a1876",
      "4d4c578db4ba4d67838c579286caa385",
      "c13fc7012bd34413b2b0a84beeafd20d",
      "9d01da5125a14e8bbcef5de67e2e4be2",
      "25b37b944c5942d7ab426db014da53e3",
      "7cbddb2210b64dab88aaa7df9862ab8c",
      "70f872470d67481ca0d394c1e4177e15",
      "a83c0907f04f4ccdb903437ff4834af4",
      "77f037c8c88b45fb89f2980f223e0510",
      "a7e1d7015261415dab0bd4abfaad5582",
      "7c222e79c7d34ff398d4de8bd5c3f656",
      "8ac615bc0aa34f208d545911827c0ca5",
      "366942a0fddd410b9a567a52f058603d",
      "e7c8df1ea3a54a979f71661870d1dca2",
      "0228853a53f84268ac292f532d3dce7f",
      "a73384c41d7343ad8198a19769efb574",
      "28677cd99ac44ae8ba489dd0abacd3e7",
      "49f98581861e437e921e7baf36750fec",
      "5b1478f4bed34204a4774a346157cdb7",
      "b08bf4598df04a73a5a2f1edcfbc7880",
      "59a424aad7f341ac8acaea6c81f8fdf8",
      "d14cc51492ae4c959c7af6b8d8978d9c",
      "ec98a7af48384a21baad11db10113e47",
      "fd39f456159541f3a806d1d6a8762a2a",
      "eceb2ef663794f9783ae899943b9a09a",
      "220fd955bc8843cca01519a59012b617",
      "be5dd83e48b0404592bfde161bc3cfda",
      "da6e7916947d4df19afde42625550429",
      "ac41bdb1d2094ad1ac17c56ea181def7",
      "5aa423488a2c41e79246735bd3b0e402",
      "1208a35fed1c4c298098191a3ec796e0",
      "00273b3837f040f4ad2bb72f21324e9d",
      "ad7cbea2c4a946058696825fd20edcbb",
      "576961b2670a4ac9a7ace603bab5ec23",
      "184faf06d2a94dd3b5a265038cb740c6",
      "47823b333857499094861f8b55e58dbf",
      "c2c221f6721a490bbf602c52473cf3d0",
      "4fdfc7de33264ee18bf18e82f65b6e9d",
      "fe2bd2b81a1f40a0a8192b6ab297aee6"
     ]
    },
    "id": "VEBjm35CzR2N",
    "outputId": "188673ed-27ed-4a4d-daef-325d09b3f7c9"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"OmidSakaki/qa_nlp_model\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"OmidSakaki/qa_nlp_model\")\n",
    "pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8LOMwcd7Ay3"
   },
   "source": [
    "# **8- Custom Question Answering (QA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XX9zDb000JaK"
   },
   "outputs": [],
   "source": [
    "pathFileForModel = '/content/gdrive/MyDrive/Copy of document_for_chatBot (1).txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDvjd_a403Lc"
   },
   "outputs": [],
   "source": [
    "with open(pathFileForModel, 'r', encoding='utf-8') as file:\n",
    "    context = file.readlines()\n",
    "    context = [''.join(context)]\n",
    "    context = context[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEwy3Axm2GZL"
   },
   "outputs": [],
   "source": [
    "def chatBot(question, context):\n",
    "    kwargs = {}\n",
    "    r = pipe(question=question, context=context, **kwargs)\n",
    "    answer = \" \".join([token.strip() for token in r[\"answer\"].strip().split() if token.strip()])\n",
    "    return(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSjg4yZc3Kef"
   },
   "outputs": [],
   "source": [
    "question = 'برنامه نویسی چیست؟'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QwCJ_6L3MON"
   },
   "outputs": [],
   "source": [
    "if question:\n",
    "    print('سوال شما : ',question)\n",
    "    response = chatBot(question, context)\n",
    "    print('جواب شما : ',response)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
